{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e1b6458df77d3e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T21:26:39.253876Z",
     "start_time": "2024-10-01T21:26:29.518476Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import tracemalloc\n",
    "tracemalloc.start()\n",
    "\n",
    "module_path = os.path.abspath(os.path.join('..'))\n",
    "if module_path not in sys.path:\n",
    "    sys.path.append(module_path)\n",
    "\n",
    "import pyeCAP\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import signal\n",
    "\n",
    "#from HF_functions import pentaPLOT, find_HF, get_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7780f0c028d97",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T21:39:22.780745Z",
     "start_time": "2024-10-01T21:39:22.164148Z"
    }
   },
   "outputs": [],
   "source": [
    "'Functions'\n",
    "def pentaPLOT(param, ECAP_channel, params_to_tank_dict, metaDF, physDF, ECAP_data, EMG_data, TriCAP_data, phys_data, phys_channel, auto_scale_factor, remove_stim_artifact = False, offsets = None, save_fig = False):\n",
    "    \n",
    "    if isinstance(param, list):\n",
    "        raise Exception(\"Param must be a single parameter, not a list.\")\n",
    "    \n",
    "    tank_ID = params_to_tank_dict[param[0]]\n",
    "    HF_duration = metaDF.loc[ metaDF['TDT Tank'] == tank_ID]['HF Duration (s)'].item()\n",
    "    \n",
    "    \"\"\"Grabs the pulse # of HF onset/offset using the standard deviation of the each pulse\"\"\"\n",
    "    HF_onset_pulse, HF_offset_pulse = find_HF(param, ECAP_data, ECAP_channel, metaDF, tank_ID, plot=False)\n",
    "    print(\"HF onset pulse #: \" + str(HF_onset_pulse))\n",
    "    print(\"HF offset pulse #: \" + str(HF_offset_pulse)) \n",
    "    \n",
    "    \"\"\"Pull time values, units converted to milliseconds.\"\"\"\n",
    "    plot_time = np.squeeze(ECAP_data.time(param) * 1e3) \n",
    "    \n",
    "    \"\"\"Pull signals for pre, during, and post-HF pulse.  Units converted to microvolts\"\"\"   \n",
    "    pre_HF_ECAP = np.squeeze(ECAP_data.mean(parameters=param, channels = ECAP_channel, bin=[0,HF_onset_pulse-1])[param]) * 1e6\n",
    "    HF_ECAP = np.squeeze(ECAP_data.mean(parameters=param, channels = ECAP_channel, bin=[HF_onset_pulse + 1,HF_offset_pulse - 1])[param]) * 1e6\n",
    "    post_HF_ECAP = np.squeeze(ECAP_data.mean(parameters=param, channels = ECAP_channel, bin=[HF_offset_pulse + 1, ECAP_data.stim.parameters.loc[param, 'pulse count']])[param]) * 1e6\n",
    "\n",
    "    pre_HF_TriCAP = np.squeeze(TriCAP_data.mean(parameters=param, channels = 0, bin=[0,HF_onset_pulse-1])[param]) * 1e6\n",
    "    HF_TriCAP = np.squeeze(TriCAP_data.mean(parameters=param, channels = 0, bin=[HF_onset_pulse + 1,HF_offset_pulse -1])[param]) * 1e6\n",
    "    post_HF_TriCAP = np.squeeze(TriCAP_data.mean(parameters=param, channels = 0, bin=[HF_offset_pulse + 1, TriCAP_data.stim.parameters.loc[param, 'pulse count']])[param]) * 1e6\n",
    "\n",
    "    pre_HF_EMG = np.squeeze(EMG_data.mean(parameters=param, bin=[0,HF_onset_pulse-1])[param]) * 1e6\n",
    "    HF_EMG = np.squeeze(EMG_data.mean(parameters=param, bin=[HF_onset_pulse + 1,HF_offset_pulse -1])[param]) * 1e6\n",
    "    post_HF_EMG = np.squeeze(EMG_data.mean(parameters=param, bin=[HF_offset_pulse + 1, EMG_data.stim.parameters.loc[param, 'pulse count']])[param]) * 1e6\n",
    "    \n",
    "    if offsets is not None:        \n",
    "        if not isinstance(offsets, list):\n",
    "            raise Exception(\"'offsets' must be a list of integer values of format [ECAP_offset, TriCAP_offset, EMG_offset] or 'None'.\")\n",
    "        else:                \n",
    "            ECAP_dy = np.std(pre_HF_ECAP) * offsets[0]\n",
    "            TriCAP_dy = np.std(pre_HF_TriCAP) * offsets[1]\n",
    "            EMG_dy = np.std(pre_HF_EMG, axis = 1) * offsets[2]\n",
    "            \n",
    "            pre_HF_ECAP = pre_HF_ECAP + ECAP_dy\n",
    "            post_HF_ECAP = post_HF_ECAP - ECAP_dy\n",
    "            \n",
    "            pre_HF_TriCAP = pre_HF_TriCAP + TriCAP_dy\n",
    "            post_HF_TriCAP = post_HF_TriCAP - TriCAP_dy\n",
    "            \n",
    "            pre_HF_EMG[0] = pre_HF_EMG[0] + EMG_dy[0]\n",
    "            post_HF_EMG[0] = post_HF_EMG[0] - EMG_dy[0]\n",
    "            pre_HF_EMG[1] = pre_HF_EMG[1] + EMG_dy[1]\n",
    "            post_HF_EMG[1] = post_HF_EMG[1] - EMG_dy[1]            \n",
    "            pre_HF_EMG[2] = pre_HF_EMG[2] + EMG_dy[2]\n",
    "            post_HF_EMG[2] = post_HF_EMG[2] - EMG_dy[2]\n",
    "    \n",
    "    fig,ax = plt.subplots(num =1, nrows = 3, ncols=2, figsize=(15,10), clear = True)\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    \"\"\" ECAP \"\"\"\n",
    "    ax[0].plot(plot_time, pre_HF_ECAP, color = 'b', label = 'Pre-HF')\n",
    "    ax[0].plot(plot_time, HF_ECAP, color = 'r', label = 'During HF')\n",
    "    ax[0].plot(plot_time, post_HF_ECAP, color = 'g', label = 'Post-HF')\n",
    "\n",
    "    if remove_stim_artifact:\n",
    "        ECAP_std_data = np.std(pre_HF_ECAP[60:])\n",
    "    else:\n",
    "        ECAP_std_data = np.std(pre_HF_ECAP)\n",
    "    \n",
    "    if offsets is not None:\n",
    "        ECAP_y_lim = [(-ECAP_std_data * auto_scale_factor) - ECAP_dy, (ECAP_std_data * auto_scale_factor) + ECAP_dy]    \n",
    "    else:        \n",
    "        ECAP_y_lim = [-ECAP_std_data * auto_scale_factor, ECAP_std_data * auto_scale_factor] \n",
    "    ax[0].set(ylim=(ECAP_y_lim[0],ECAP_y_lim[1]), xlim=(0,20), title='ECAP', ylabel = 'Voltage (uV)')\n",
    "    ax[0].legend(loc='upper right')\n",
    "\n",
    "    \"\"\"Tripolar ECAP\"\"\"\n",
    "    ax[1].plot(plot_time, pre_HF_TriCAP, color = 'b', label = 'Pre-HF')\n",
    "    ax[1].plot(plot_time, HF_TriCAP, color = 'r', label = 'During HF')\n",
    "    ax[1].plot(plot_time, post_HF_TriCAP, color = 'g', label = 'Post-HF')\n",
    "\n",
    "    if remove_stim_artifact:\n",
    "        triCAP_std_data = np.std(pre_HF_TriCAP[60:])\n",
    "    else:\n",
    "        triCAP_std_data = np.std(pre_HF_TriCAP)\n",
    "\n",
    "    if offsets is not None:\n",
    "        triCAP_y_lim = [(-triCAP_std_data * auto_scale_factor) - TriCAP_dy, (triCAP_std_data * auto_scale_factor) + TriCAP_dy]    \n",
    "    else:\n",
    "        triCAP_y_lim = [-triCAP_std_data * auto_scale_factor, triCAP_std_data * auto_scale_factor] \n",
    "    ax[1].set(ylim=(triCAP_y_lim[0],triCAP_y_lim[1]), xlim=(0,20), title='Tripolar ECAP', ylabel = 'Voltage (uV)')\n",
    "    ax[1].legend(loc='upper right')\n",
    "\n",
    "    #TODO: Add EMG channel ID's to metadata DF so that the function can autoplot the correct EMG\n",
    "    \"\"\" CA EMG \"\"\"\n",
    "    CA_chan = metaDF.loc[ metaDF['TDT Tank'] == tank_ID]['CA EMG Channel'].item()\n",
    "\n",
    "    ax[2].plot(plot_time, pre_HF_EMG[CA_chan], color = 'b', label = 'Pre-HF')\n",
    "    ax[2].plot(plot_time, HF_EMG[CA_chan], color = 'r', label = 'During HF')\n",
    "    ax[2].plot(plot_time, post_HF_EMG[CA_chan], color = 'g', label = 'Post-HF')\n",
    "    \n",
    "    EMG1_std_data = np.std(pre_HF_EMG[CA_chan])\n",
    "    if offsets is not None:\n",
    "        EMG1_y_lim = [(-EMG1_std_data * auto_scale_factor) - EMG_dy[CA_chan], (EMG1_std_data * auto_scale_factor) + EMG_dy[CA_chan]]    \n",
    "    else:\n",
    "        EMG1_y_lim = [-EMG1_std_data * auto_scale_factor, EMG1_std_data * auto_scale_factor] \n",
    "\n",
    "    ax[2].legend(loc='upper right')\n",
    "    ax[2].set(ylabel = 'Voltage (uV)', title='Cricoarytenoid EMG', xlim = (0,20), ylim=(EMG1_y_lim[0],EMG1_y_lim[1]))\n",
    "\n",
    "    \"\"\"CT EMG\"\"\"\n",
    "    CT_chan = metaDF.loc[ metaDF['TDT Tank'] == tank_ID]['CT EMG Channel'].item()\n",
    "\n",
    "    ax[3].plot(plot_time, pre_HF_EMG[CT_chan], color = 'b', label = 'Pre-HF')\n",
    "    ax[3].plot(plot_time, HF_EMG[CT_chan], color = 'r', label = 'During HF')\n",
    "    ax[3].plot(plot_time, post_HF_EMG[CT_chan], color = 'g', label = 'Post-HF')\n",
    "\n",
    "    EMG2_std_data = np.std(pre_HF_EMG[CT_chan])\n",
    "    if offsets is not None:\n",
    "        EMG2_y_lim = [(-EMG2_std_data * auto_scale_factor) - EMG_dy[CT_chan], (EMG2_std_data * auto_scale_factor) + EMG_dy[CT_chan]]    \n",
    "    else:\n",
    "        EMG2_y_lim = [-EMG2_std_data * auto_scale_factor, EMG2_std_data * auto_scale_factor] \n",
    "\n",
    "    ax[3].legend(loc='upper right')\n",
    "    ax[3].set(xlabel = 'Time (ms)', title='Cricothyroid EMG', xlim = (0,20), ylim=(EMG2_y_lim[0],EMG2_y_lim[1]))\n",
    "\n",
    "    \"\"\" Cardiac \"\"\"\n",
    "    physDF_idx = physDF.loc[ physDF['Stim Parameter'] == param].index\n",
    "    HR_plot_start = physDF.loc[physDF_idx, 'Start Index'].item() - 30001\n",
    "    HR_plot_stop = physDF.loc[physDF_idx, 'Stop Index'].item() + 30001\n",
    "    HR_plot_time = np.arange(0, (HR_plot_stop - HR_plot_start) / 1000, .001)\n",
    "\n",
    "    #For adding shading to plot\n",
    "    pulse_start = 30001\n",
    "    pulse_duration = physDF.loc[physDF_idx, 'Stop Index'].item() - physDF.loc[physDF_idx, 'Start Index'].item()\n",
    "    pulse_stop = pulse_start + pulse_duration\n",
    "    pulse_window = (pulse_start / 1000, pulse_stop / 1000)\n",
    "\n",
    "    phys_ch_slice = phys_data._ch_to_index(phys_channel)\n",
    "\n",
    "    ax[4].plot(HR_plot_time, np.squeeze(phys_data.array[phys_ch_slice, HR_plot_start:HR_plot_stop]))\n",
    "    ax[4].set( ylabel = 'HR (bpm)', title='Cardiac')\n",
    "\n",
    "    #Tonic Stim window\n",
    "    ax[4].axvspan(pulse_window[0], pulse_window[1], color = 'b', alpha = 0.1, label='Tonic Stim')\n",
    "\n",
    "    #HF window\n",
    "    HF_start = 30 + metaDF.loc[ metaDF['TDT Tank'] == tank_ID, 'HF Delay (s)'].item()  #30 is from the 30 second pre-tonic stim plot window\n",
    "    HF_stop = HF_start + HF_duration\n",
    "\n",
    "    ax[4].axvspan(HF_start, HF_stop, color = 'r', alpha = 0.3, label='HF')\n",
    "    ax[4].legend(loc='upper right')\n",
    "\n",
    "    fig_title = metaDF.loc[ metaDF['TDT Tank'] == tank_ID]['Type'].item() + ': '\\\n",
    "                + str(metaDF.loc[ metaDF['TDT Tank'] == tank_ID]['HF Amplitude (mA)'].item()) + ' mA HF || '\\\n",
    "                + str(abs(stimDF.loc[param, 'pulse amplitude (μA)']) / 1000) + ' mA LF ' + 'Ch. ' + str(stimDF.loc[param, 'channel'])\\\n",
    "                + ' || ' + str(param)\n",
    "\n",
    "    save_title = metaDF.loc[ metaDF['TDT Tank'] == tank_ID]['Type'].item() + '_'\\\n",
    "               + str(metaDF.loc[ metaDF['TDT Tank'] == tank_ID]['HF Amplitude (mA)'].item()) + '_ma_HF_Ch'\\\n",
    "                + str(stimDF.loc[param, 'channel'])+'_StimAmp_'+ str(int(abs(stimDF.loc[param, 'pulse amplitude (μA)'])))+'_' + str(param)+'.png'\n",
    "    print(save_title)\n",
    "    fig.suptitle(fig_title)\n",
    "    fig.tight_layout()\n",
    "\n",
    "    if save_fig == True:\n",
    "        fig.savefig(save_title, format='png')\n",
    "        fig.clear()\n",
    "        plt.clf()\n",
    "        plt.close()\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def ADI_align(phys_data, ADI_filePATH, metaDF, stim):\n",
    "    \"\"\" Physiology Data Import\"\"\"\n",
    "    comMATRIX = sio.loadmat(ADI_filePATH)\n",
    "    \n",
    "    \"\"\"Import comments into new more accessible DF and align them with sample #'s of the entire file\"\"\"\n",
    "    comDF = pd.DataFrame()\n",
    "    comDF[['Comment Text' ,'Sample #', 'Stim Train ID']] = \"\"\n",
    "    comDF['Comment Matrix ID'] = comMATRIX['com'][:,4]\n",
    "    \n",
    "    for i,V in enumerate(comDF['Comment Matrix ID']): \n",
    "        comDF.loc[i, 'Comment Text'] = comMATRIX['comtext'][int(V-1)].strip()\n",
    "    \n",
    "    #Calculates the # samples per ADI block\n",
    "    blockLENGTHS = comMATRIX['dataend'] - comMATRIX['datastart']\n",
    "    blockIDX = []\n",
    "    \n",
    "    #Constructs a list of tuples containing the start and stop indices of each ADI block.\n",
    "    #This is necessary to find the exact sample # of each comment due to how they are mapped by ADI i.e. the 'com' array gives the index of the comment within the block it was made -- not for the whole file\n",
    "    for i,V in enumerate(blockLENGTHS[0,:]):\n",
    "        if i == 0:\n",
    "            blockIDX.append((0,V))\n",
    "            off = V\n",
    "        else:\n",
    "            on = off + 1\n",
    "            off = off + V\n",
    "            blockIDX.append((on,off))\n",
    "    \n",
    "    #Iterate through comments matrix to find the index values of the comments and assigns them to the comment list\n",
    "    for i,V in enumerate(comMATRIX['com']):\n",
    "        blockNUM = int(V[1] - 1) #V[1] is the block that # that the comment was made in.  Subtract 1 to get it into python indexing (starts @ 0)    \n",
    "        comDF.loc[i, 'Sample #'] = blockIDX[blockNUM][0] + V[2] #blockIDX[blockNUM][0] = Starting sample # of the block the comment is in.  V[2] is the sample # within that block that the comment was made.\n",
    "    \n",
    "    \"\"\" Code segment which looks for on/offs in the stim output from the TDT to ADI.  If the ADI data is noisy or messed up this may need tweaking.  Generally, there should be an equal number of start / stop indices assuming the system started with the stim trigger output on 0V.\"\"\"\n",
    "    phys_ch_slice = phys_data._ch_to_index('Stim Trigger')\n",
    "    dataDF = pd.DataFrame(data = np.squeeze(phys_data.array[phys_ch_slice].compute()), columns=['Stim Trigger'])\n",
    "    \n",
    "    start_idx = dataDF.loc[(dataDF['Stim Trigger'] > 2.5) & (dataDF['Stim Trigger'].shift() <2.5) & (dataDF['Stim Trigger'].shift(10) < 0.5)].index\n",
    "    print('Found ' + str(len(start_idx)) + ' start indices')\n",
    "    stop_idx = dataDF.loc[(dataDF['Stim Trigger'] < 0.5) & (dataDF['Stim Trigger'].shift() > 0.5) & (dataDF['Stim Trigger'].shift(10) > 3)].index\n",
    "    #TODO: make this an if statement check?\n",
    "    #stop_idx = stop_idx[1:] #This line removes the first element of the stop indices that would occur if the system started with the stim trigger ouput at 3.3V\n",
    "    print('Found ' + str(len(stop_idx)) + ' stop indices')\n",
    "    \n",
    "    \"\"\"Creates a dataframe for mapping comments to stim pulse trains\"\"\"\n",
    "    mapDF = pd.DataFrame(columns = ['Comment Text', 'Start Index', 'Stop Index', 'Stim Parameter', 'Max HR Change'])\n",
    "    \n",
    "    \"\"\"Assigns start/stop indexes every pulse train (in order)\"\"\"\n",
    "    mapDF['Start Index'] = start_idx\n",
    "    mapDF['Stop Index'] = stop_idx\n",
    "    mapDF['#Samples/Stim Train'] = mapDF['Stop Index'] - mapDF['Start Index']\n",
    "    \n",
    "    \"\"\" Lines up the comments with the pulse train by finding the closest pulse train start sample # to the comment's sample # \"\"\"\n",
    "    for i,V in enumerate(comDF['Sample #']):\n",
    "       dist = (mapDF['Start Index'] - V).abs()\n",
    "       mapDF.loc[dist.idxmin(), 'Comment Text'] = comDF['Comment Text'][i]\n",
    "    \n",
    "    \"\"\"Up to this point everything has been done with just ADI data. The code below pulls in data from the stimulation\n",
    "    object of pyeCAP to match up the stim parameters with the ADI data.\"\"\"\n",
    "    \n",
    "    \"\"\"Finds the pulse train # which lines up with the specific comment corresponding to each TDT tank.\"\"\"\n",
    "    comment_to_pulse_indicies = []\n",
    "    for idx,com in enumerate(metaDF['ADI File Comment']):\n",
    "        try:\n",
    "            comment_to_pulse_indicies.append(mapDF.index[mapDF['Comment Text'] == com][0])\n",
    "        except IndexError:\n",
    "            traceback.print_exc()\n",
    "            print('Could not find a comment match for TDT Tank: ' + metaDF.loc[idx, 'TDT Tank'])\n",
    "            print('Erred Comment: ' + str(com))\n",
    "            break\n",
    "    #comment_to_pulse_indicies = [mapDF.index[mapDF['Comment Text'] == com][0] for com in metaDF['ADI File Comment']]\n",
    "    \n",
    "    \"\"\"Maps the individual pulse trains to their specific stim index parameters\"\"\"\n",
    "    stats_index_dict = {key:value for (key,value) in zip(metaDF['TDT Tank'].to_list(), comment_to_pulse_indicies)}\n",
    "    grouped_parameters = stim.parameters.groupby(level=0).groups\n",
    "    \n",
    "    for tank_idx, tank in enumerate(metaDF['TDT Tank'].to_list()):\n",
    "        for i in np.arange(grouped_parameters[tank_idx].size):\n",
    "            mapDF.at[stats_index_dict[tank] + i, 'Stim Parameter'] = grouped_parameters[tank_idx][i]\n",
    "    return mapDF\n",
    "\n",
    "def get_parameters(type=None, HF_amp = None, LF_amp = None, stim_ch = None):\n",
    "    paramLIST = []\n",
    "    #Only Type is given\n",
    "    if type is not None and HF_amp is None and LF_amp is None and stim_ch is None:\n",
    "        tanks = metaDF.loc[(metaDF['Type'] == type)]['TDT Tank'].to_list()\n",
    "        for tank in tanks:\n",
    "            paramLIST.extend(tank_to_params_dict[tank].to_list())\n",
    "    #Only HF_amp is given\n",
    "    elif type is None and HF_amp is not None and LF_amp is None and stim_ch is None:\n",
    "        tanks = metaDF.loc[ (metaDF['HF Amplitude (mA)'] == HF_amp)]['TDT Tank'].to_list()\n",
    "        for tank in tanks:\n",
    "            paramLIST.extend(tank_to_params_dict[tank].to_list())\n",
    "    #Only Type and HF amp are given\n",
    "    elif type is not None and HF_amp is not None and LF_amp is None and stim_ch is None:\n",
    "        tanks = metaDF.loc[ (metaDF['Type'] == type) & (metaDF['HF Amplitude (mA)'] == HF_amp)]['TDT Tank'].item()\n",
    "        paramLIST.extend(tank_to_params_dict[tanks])  \n",
    "    else:\n",
    "        tank = metaDF.loc[ (metaDF['Type'] == type) & (metaDF['HF Amplitude (mA)'] == HF_amp)]['TDT Tank'].item()\n",
    "        paramDF = stim.parameters.loc[tank_to_params_dict[tank]]\n",
    "        paramLIST = paramDF.loc[ (paramDF['pulse amplitude (μA)'] == LF_amp) & (paramDF['channel'] == stim_ch)].index.item()\n",
    "    return paramLIST\n",
    "\n",
    "def find_HF(param, ECAP_data, ECAP_channel, metaDF, tank_ID, plot = False):\n",
    "    data = ECAP_data.array(param, ECAP_channel)[param]\n",
    "    pulse_std = np.std(data, axis=2) ** 2\n",
    "    \n",
    "    HF_delay = metaDF.loc[ metaDF['TDT Tank'] == tank_ID, 'HF Delay (s)'].item()\n",
    "    HF_duration = metaDF.loc[ metaDF['TDT Tank'] == tank_ID, 'HF Duration (s)'].item()\n",
    "    \n",
    "    pulses_per_sec = ECAP_data.stim.parameters.at[param, 'frequency (Hz)']\n",
    "    baseline_pulse_stop = int((HF_delay - 1) * pulses_per_sec)\n",
    "    baseline = np.mean(pulse_std[ 0 : baseline_pulse_stop])  #Mean st.dev during baseline period\n",
    "    \n",
    "    HF_window_start = int( (HF_delay + 2) * pulses_per_sec)\n",
    "    HF_window_stop = int(( HF_delay + HF_duration - 2) * pulses_per_sec)\n",
    "    HF = np.mean(pulse_std[ HF_window_start : HF_window_stop ])  #Mean st.dev during HF period\n",
    "    \n",
    "    HF_threshold = HF - ((HF - baseline)*0.5) #Mean of HF period - ((Mean of HF period - Mean of baseline) * 0.5) \n",
    "    #HF_threshold = 5 * baseline\n",
    "    \n",
    "    HF_indices = np.nonzero(pulse_std > HF_threshold)[0]\n",
    "    HF_onset_pulse = HF_indices[0]\n",
    "    HF_offset_pulse = HF_indices[-1]\n",
    "    \n",
    "    if plot:\n",
    "        plt.plot(np.arange(data.shape[0]), pulse_std)\n",
    "        #plt.axhline(baseline, color='c')\n",
    "        #plt.axhline(HF, color='g')\n",
    "        plt.axhline(HF_threshold, color='r')\n",
    "        plt.show()\n",
    "    \n",
    "    return [HF_onset_pulse, HF_offset_pulse]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a545088e7aa550f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T21:36:24.496572Z",
     "start_time": "2024-10-01T21:36:14.511478Z"
    }
   },
   "outputs": [],
   "source": [
    "\"Import meta data\"\n",
    "\"\"\"Get HF meta data from excel file\"\"\"\n",
    "excel_path = r'E:\\HF_Block\\20240904_HFBlock_Pig05\\20240904_HFBlock_05_Parameters_modified.xlsx'\n",
    "metaDF = pd.read_excel(excel_path, sheet_name = 'HF05_metaDF')\n",
    "\n",
    "\"\"\"Remove rows that are not needed for current analysis and reset index of metaDF\"\"\"\n",
    "metaDF.drop(metaDF.loc[ metaDF['Type'] == 'HF Only'].index, inplace = True)  #Removed HF only tanks as they did not have any stim parameters\n",
    "metaDF.drop(metaDF.loc[ metaDF['Type'] == 'Control'].index, inplace = True)\n",
    "metaDF.drop(metaDF.loc[ metaDF['Type'] == 'X'].index, inplace = True)\n",
    "metaDF.drop(metaDF.loc[ metaDF['Type'] == 'Thresholding'].index, inplace = True)\n",
    "metaDF.drop(metaDF.loc[ metaDF['Type'] == 'Contact ID'].index, inplace = True)\n",
    "metaDF.reset_index(inplace = True)\n",
    "\n",
    "\"TDT Data Import - List\"\n",
    "tdt_path = r'E:\\HF_Block\\20240904_HFBlock_Pig05\\HF_Block_Template-240904-083702' #Lab Path\n",
    "#tdt_path = r'G:\\Data\\HF_Block\\20240904_HFBlock_Pig05\\HF_Block_Template-240904-083702' #Local Path \n",
    "tdt_file_list_all = os.listdir(tdt_path)\n",
    "tdt_file_list_all.remove('desktop.ini')\n",
    "\n",
    "ADI_path = r'E:\\HF_Block\\20240904_HFBlock_Pig05' #Lab Path\n",
    "#ADI_path = r'G:\\Data\\HF_Block\\20240904_HFBlock_Pig05' #Local path\n",
    "ADI_file = r'\\20240904_HFBlock_Pig05_stats_modified.mat'\n",
    "\n",
    "raw_phys = pyeCAP.Phys(ADI_path + ADI_file, mult_data=False)\n",
    "ws_stripped_names = [i.strip() for i in raw_phys.ch_names] #This line just removes the white spaces around the names imported\n",
    "raw_phys = raw_phys.set_ch_names(ws_stripped_names)\n",
    "\n",
    "\"\"\"Ephys data instantiation\"\"\"\n",
    "tdt_path_list = [tdt_path + '\\\\' + fileNAME for fileNAME in metaDF['TDT Tank']]\n",
    "\n",
    "#Data Streams\n",
    "raw_ECAP = pyeCAP.Ephys(tdt_path_list, stores = 'ECAP')\n",
    "raw_ECAP = raw_ECAP.remove_ch(['ECAP 6', 'ECAP 7', 'ECAP 8'])\n",
    "\n",
    "raw_triCAP = pyeCAP.Ephys(tdt_path_list, stores = 'TriP')\n",
    "raw_triCAP = raw_triCAP.remove_ch(['TriP 2', 'TriP 3', 'TriP 4'])\n",
    "\n",
    "raw_EMG = pyeCAP.Ephys(tdt_path_list, stores='EMGG')\n",
    "raw_EMG = raw_EMG.remove_ch(['EMGG 4'])\n",
    "\n",
    "\"\"\"Changes the stim multi-index to utilize the Tank names from tdt_file_list instead [0,1,2,3...]\"\"\"\n",
    "stim = pyeCAP.Stim(tdt_path_list)\n",
    "stimDF = stim.parameters\n",
    "tank_to_params_dict = { tank:params for (tank,params) in zip(metaDF['TDT Tank'].to_list(), stim.parameters.groupby(level=0).groups.values() ) }\n",
    "params_to_tank_dict = { param:tank for (param,tank) in zip(stim.parameters.groupby(level=0).groups.keys(), metaDF['TDT Tank'].to_list()) }\n",
    "\n",
    "#HF output from Keithley DAQ\n",
    "HF_output = pyeCAP.Ephys(tdt_path_list, stores='HF_a')\n",
    "\n",
    "\"\"\"Filtering - Standard\"\"\"\n",
    "#raw_ECAP_f = raw_ECAP.filter_powerline()\n",
    "raw_ECAP_f = raw_ECAP.filter_gaussian(Wn=5000, btype='lowpass')\n",
    "raw_ECAP_f = raw_ECAP_f.filter_median(btype='highpass')\n",
    "\n",
    "#raw_triCAP_f = raw_triCAP.filter_powerline()\n",
    "raw_triCAP_f = raw_triCAP.filter_gaussian(Wn=5000, btype='lowpass')\n",
    "raw_triCAP_f = raw_triCAP_f.filter_median(btype='highpass')\n",
    "\n",
    "#raw_EMG_f = raw_EMG.filter_powerline()\n",
    "raw_EMG_f = raw_EMG.filter_gaussian(Wn=5000, btype='lowpass')\n",
    "raw_EMG_f = raw_EMG_f.filter_median(btype='highpass')\n",
    "\n",
    "\"\"\"ECAP/EMG/TriCAP object instantiation\"\"\"\n",
    "ECAPr = pyeCAP.ECAP(raw_ECAP, stim)\n",
    "triCAPr = pyeCAP.ECAP(raw_triCAP, stim)\n",
    "ECAPf = pyeCAP.ECAP(raw_ECAP_f, stim)\n",
    "triCAPf = pyeCAP.ECAP(raw_triCAP_f, stim)\n",
    "EMGr = pyeCAP.EMG(raw_EMG, stim)\n",
    "EMGf = pyeCAP.EMG(raw_EMG_f, stim)\n",
    "\n",
    "\"Align stimulations with ADI data\"\n",
    "#physDF = ADI_align(phys_data, ADI_path + ADI_file, metaDF, stim=stim)\n",
    "PHYSr = pyeCAP.ECAP(raw_phys,stim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9a54a8771ae589",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Onset/Offset analysis\n",
    "#Get an RMS on a pulse by pulse basis\n",
    "#Plot that RMS across periods of HF onset/offset\n",
    "#Array returns a dictionary of data with the key = parameter tuple and value = data of pulses and channels\n",
    "#Need to iterate through that somehow if multiple parameters get passed and return a new dictionary of RMS values\n",
    "#RMS array should have one value per pulse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48ee2ac2d0ea941",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T21:39:32.799639Z",
     "start_time": "2024-10-01T21:39:32.776250Z"
    }
   },
   "outputs": [],
   "source": [
    "\"\"\"Testing using ECAPr pulse RMS to find HF\"\"\"\n",
    "files = metaDF['TDT Tank'].loc[ metaDF['Type'] == 'EMG DRC'].values.tolist()\n",
    "params = get_parameters(type='EMG DRC')\n",
    "plot_params = get_parameters(type='EMG DRC', HF_amp=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "202225fbdf5c5b9f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T21:39:36.616410Z",
     "start_time": "2024-10-01T21:39:33.163010Z"
    }
   },
   "outputs": [],
   "source": [
    "for param in plot_params:\n",
    "    HF_onset, HF_offset = find_HF(param, ECAPr, ECAP_channel=0, metaDF=metaDF, tank_ID=params_to_tank_dict[param[0]], plot=True)\n",
    "    print(param)\n",
    "    print(HF_onset, HF_offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97f503361f8011e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T21:54:17.197586Z",
     "start_time": "2024-10-01T21:54:16.394575Z"
    }
   },
   "outputs": [],
   "source": [
    "param = (3,0)\n",
    "bin = [335,336]\n",
    "ECAPr.plot_binned_traces(parameter = param, channel=0, bin=bin, y_lim = (-100,100))\n",
    "\n",
    "data = ECAPr.array(param, 0)[param]\n",
    "tank_ID = params_to_tank_dict[param[0]]\n",
    "\n",
    "pulse_std = np.std(data, axis=2)  #Array of a single standard deviation values for each pulse\n",
    "\n",
    "HF_delay = metaDF.loc[metaDF['TDT Tank'] == tank_ID, 'HF Delay (s)'].item()\n",
    "HF_duration = metaDF.loc[metaDF['TDT Tank'] == tank_ID, 'HF Duration (s)'].item()\n",
    "\n",
    "pulses_per_sec = ECAPr.stim.parameters.at[param, 'frequency (Hz)']\n",
    "baseline_pulse_stop = int((HF_delay - 1) * pulses_per_sec)\n",
    "baseline = np.mean(pulse_std[0: baseline_pulse_stop])\n",
    "\n",
    "HF_window_start = int((HF_delay + 2) * pulses_per_sec)\n",
    "HF_window_stop = int((HF_delay + HF_duration - 2) * pulses_per_sec)\n",
    "HF = np.mean(pulse_std[HF_window_start: HF_window_stop])\n",
    "#HF_threshold = HF - ((HF - baseline) * 0.33)\n",
    "HF_threshold = 5 * baseline\n",
    "\n",
    "HF_indices = np.nonzero(pulse_std > HF_threshold)[0]\n",
    "HF_onset_pulse = HF_indices[0]\n",
    "HF_offset_pulse = HF_indices[-1]\n",
    "\n",
    "#Iterate through each pulse and find the first pulse where np.max greater than some value?\n",
    "\n",
    "#HF_stop_threshold = HF - ((HF - baseline) * 0.33)\n",
    "#HF_stop_indices = np.nonzero(pulse_std < HF_stop_threshold)[0]\n",
    "#First value in HF_stop_indices that is after the HF_onset_pulse value\n",
    "#HF_stop_idx2 = np.nonzero(HF_stop_indices > HF_onset_pulse)[0]\n",
    "#print(HF_stop_idx2)\n",
    "#HF_offset_pulse = HF_stop_indices[HF_stop_idx2[0]]\n",
    "\n",
    "print(HF_onset_pulse,HF_offset_pulse)\n",
    "plt.plot(np.arange(data.shape[0]), pulse_std)\n",
    "#plt.axhline(baseline, color='c')\n",
    "#plt.axhline(HF, color='g')\n",
    "plt.axhline(HF_threshold, color='r')\n",
    "plt.xlim(bin[0], bin[1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eace1a6285038e52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T21:54:34.836943Z",
     "start_time": "2024-10-01T21:54:34.813257Z"
    }
   },
   "outputs": [],
   "source": [
    "testdata = ECAPr.array(param, 0)[param]\n",
    "testdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9a13a3ce51ca5a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T21:54:58.815031Z",
     "start_time": "2024-10-01T21:54:58.256050Z"
    }
   },
   "outputs": [],
   "source": [
    "ser = pd.Series(np.squeeze(testdata[137]))\n",
    "plt.plot(ser)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25858fbc6d119284",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T21:55:11.323065Z",
     "start_time": "2024-10-01T21:55:11.024340Z"
    }
   },
   "outputs": [],
   "source": [
    "ser = pd.Series(np.squeeze(testdata[137]))\n",
    "rolling_output = ser.rolling(250).std() * 1e6\n",
    "\n",
    "plt.plot(rolling_output)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4173ac36fb458805",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T21:55:21.052490Z",
     "start_time": "2024-10-01T21:55:20.741077Z"
    }
   },
   "outputs": [],
   "source": [
    "ser = pd.Series(np.squeeze(testdata[137]))\n",
    "rolling_output = ser.rolling(250).std() * 1e6\n",
    "\n",
    "plt.plot(rolling_output)\n",
    "plt.axhline(HF_threshold*1e6, color='r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec60966465e4f18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T21:50:47.845538Z",
     "start_time": "2024-10-01T21:50:47.832798Z"
    }
   },
   "outputs": [],
   "source": [
    "250 * 1 / ECAPr.sample_rate * 1e3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69708b7b6fc288d3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-01T21:52:50.329884Z",
     "start_time": "2024-10-01T21:52:50.268217Z"
    }
   },
   "outputs": [],
   "source": [
    "stimDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "211154fee8009598",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = metaDF['TDT Tank'].loc[ metaDF['Type'] == 'EMG DRC'].values.tolist()\n",
    "pulse_RMS = {}\n",
    "for file in files:\n",
    "    print(file)\n",
    "    pulse_RMS.update( EMGf.pulse_RMS(parameters = tank_to_params_dict[file].tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a51c79c77713306",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = get_parameters(type = 'EMG DRC', HF_amp=0.5)\n",
    "chan = 1\n",
    "for param in params:\n",
    "    fig,ax = plt.subplots(figsize=(10,5))\n",
    "    ax.plot(np.arange(pulse_RMS[param].shape[0]), pulse_RMS[param][:,chan])  \n",
    "    ax.set(title=param)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78772828b5a31873",
   "metadata": {},
   "outputs": [],
   "source": [
    "onset,offset = find_HF((0,8), ECAPr, ECAP_channel=0, metaDF = metaDF, tank_ID='HF05-240904-120445', plot=True)\n",
    "print(onset)\n",
    "print(offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef871e473ee42ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = (0,8)\n",
    "EMGf.plot_binned_traces(parameter = param, channel=1, bin=[130,140], y_lim = (-50,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f128d5940f5786a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig,ax = plt.subplots(figsize=(10,5))\n",
    "ax.plot(np.arange(pulse_RMS[param].shape[0]), pulse_RMS[param][:,chan])  \n",
    "ax.set(title=param)#, xlim=(0,100))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d74c98814d47b594",
   "metadata": {},
   "outputs": [],
   "source": [
    "param = (0,0)\n",
    "ECAPr.plot_binned_traces(parameter = param, channel=0, bin=[130,133], y_lim = (-50,50))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
